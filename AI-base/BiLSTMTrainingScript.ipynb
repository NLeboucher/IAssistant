{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BiLSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# Ensures that the same sequence of random numbers will be generated every time.\n",
    "# Sets the seed for generating random numbers in a torch.Generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<torchtext.data.field.LabelField object at 0x7f9b54d5ec20>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEXT = data.Field(tokenize=tokenizer, lower = True)\n",
    "LABEL = data.LabelField()\n",
    "print(TEXT.dtype)\n",
    "print(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading snli_1.0.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "snli_1.0.zip: 100%|██████████| 94.6M/94.6M [02:00<00:00, 784kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = datasets.SNLI.splits(TEXT, LABEL)\n",
    "#loading data from the SNLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [09:22, 1.53MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:22<00:00, 17631.70it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"glove.6B.300d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "#building the vocabulary for the text and label fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 300\n",
    "N_LSTM_LAYERS = 2\n",
    "N_FC_LAYERS = 3\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 23551Unique tokens in LABEL vocabulary: 3Debug: These two lines should show be the same words (for TEXT) \n",
      "[('a', 1438991), ('.', 962527), ('the', 534692), ('in', 407296), ('is', 373543), ('man', 266236), ('on', 235904), ('and', 206363), ('are', 199114), ('of', 192428), ('with', 169236), ('woman', 137630), ('two', 122259), ('people', 121154), (',', 114331), ('to', 113972), ('at', 98656), ('wearing', 81024), ('an', 80212), ('his', 72467)]['<unk>', '<pad>', 'a', '.', 'the', 'in', 'is', 'man', 'on', 'and', 'are', 'of', 'with', 'woman', 'two', 'people', ',', 'to', 'at', 'wearing']Debug: These two lines should show be the same words (for LABEL)[('entailment', 183416), ('contradiction', 183187), ('neutral', 182764)]['entailment', 'contradiction', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\"\n",
    "        f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\"\n",
    "        f\"Debug: These two lines should show be the same words (for TEXT) \\n{TEXT.vocab.freqs.most_common(20)}\"\n",
    "        f\"{TEXT.vocab.itos[:20]}\" #showing the most common words in the vocabulary good if they are the same as the above frequency list\n",
    "\n",
    "        f\"Debug: These two lines should show be the same words (for LABEL){LABEL.vocab.freqs.most_common()}\" #showing the frequency of the labels in the vocabulary\n",
    "        f\"{LABEL.vocab.itos}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda, gpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "# creating iterators for the data \n",
    "print(f\"{device}, {'gpu' if device == torch.device('cuda') else 'slow training on cpu'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = BiLSTM.NLIBiLSTM(INPUT_DIM,\n",
    "                  EMBEDDING_DIM,\n",
    "                  HIDDEN_DIM,\n",
    "                  N_LSTM_LAYERS,\n",
    "                  N_FC_LAYERS,\n",
    "                  OUTPUT_DIM,\n",
    "                  DROPOUT,\n",
    "                  PAD_IDX).to(device)\n",
    "# creating the model\n",
    "#print(model.sumary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23551, 300])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "# getting the pretrained embeddings\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n",
       "        [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n",
       "        [-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
       "        ...,\n",
       "        [-0.2149,  0.0846, -0.2949,  ...,  0.2379,  0.4804, -0.3348],\n",
       "        [-1.0809, -1.1397, -0.9308,  ..., -1.6457,  0.5161, -1.6925],\n",
       "        [ 0.3580, -0.0304,  0.3355,  ...,  0.0703, -0.5158,  0.1819]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "        ...,\n",
      "        [-0.2149,  0.0846, -0.2949,  ...,  0.2379,  0.4804, -0.3348],\n",
      "        [-1.0809, -1.1397, -0.9308,  ..., -1.6457,  0.5161, -1.6925],\n",
      "        [ 0.3580, -0.0304,  0.3355,  ...,  0.0703, -0.5158,  0.1819]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "# setting the padding index to zero\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has  15092403 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model): } trainable parameters')\n",
    "tempcount_parameters=count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.requires_grad = False\n",
    "# setting the embedding layer to not be trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has  8027103 unfrozen trainable parameters and we froze 7,065,300\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):} unfrozen trainable parameters and we froze {(tempcount_parameters-count_parameters(model)):,}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.cuda.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        prem = batch.premise\n",
    "        hypo = batch.hypothesis\n",
    "        labels = batch.label\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #prem = [prem sent len, batch size]\n",
    "        #hypo = [hypo sent len, batch size]\n",
    "        \n",
    "        predictions = model(prem, hypo)\n",
    "        \n",
    "        #predictions = [batch size, output dim]\n",
    "        #labels = [batch size]\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            prem = batch.premise\n",
    "            hypo = batch.hypothesis\n",
    "            labels = batch.label\n",
    "                        \n",
    "            predictions = model(prem, hypo)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "                \n",
    "            acc = categorical_accuracy(predictions, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 4m 58s\n",
      "\tTrain Loss: 0.770 | Train Acc: 65.80%\n",
      "\t Val. Loss: 0.668 |  Val. Acc: 72.12%\n",
      "Epoch: 02 | Epoch Time: 4m 59s\n",
      "\tTrain Loss: 0.630 | Train Acc: 73.90%\n",
      "\t Val. Loss: 0.606 |  Val. Acc: 75.03%\n",
      "Epoch: 03 | Epoch Time: 5m 0s\n",
      "\tTrain Loss: 0.573 | Train Acc: 76.78%\n",
      "\t Val. Loss: 0.558 |  Val. Acc: 77.30%\n",
      "Epoch: 04 | Epoch Time: 5m 1s\n",
      "\tTrain Loss: 0.533 | Train Acc: 78.68%\n",
      "\t Val. Loss: 0.539 |  Val. Acc: 78.19%\n",
      "Epoch: 05 | Epoch Time: 5m 7s\n",
      "\tTrain Loss: 0.502 | Train Acc: 80.14%\n",
      "\t Val. Loss: 0.523 |  Val. Acc: 78.89%\n",
      "Epoch: 06 | Epoch Time: 5m 7s\n",
      "\tTrain Loss: 0.474 | Train Acc: 81.40%\n",
      "\t Val. Loss: 0.504 |  Val. Acc: 79.80%\n",
      "Epoch: 07 | Epoch Time: 5m 9s\n",
      "\tTrain Loss: 0.448 | Train Acc: 82.54%\n",
      "\t Val. Loss: 0.501 |  Val. Acc: 80.00%\n",
      "Epoch: 08 | Epoch Time: 5m 7s\n",
      "\tTrain Loss: 0.423 | Train Acc: 83.62%\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 80.84%\n",
      "Epoch: 09 | Epoch Time: 5m 7s\n",
      "\tTrain Loss: 0.397 | Train Acc: 84.74%\n",
      "\t Val. Loss: 0.504 |  Val. Acc: 80.76%\n",
      "Epoch: 10 | Epoch Time: 5m 7s\n",
      "\tTrain Loss: 0.371 | Train Acc: 85.80%\n",
      "\t Val. Loss: 0.504 |  Val. Acc: 81.21%\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.513 |  Test Acc: 80.17%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_inference(premise, hypothesis, text_field, label_field, model, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(premise, str):\n",
    "        premise = text_field.tokenize(premise)\n",
    "    \n",
    "    if isinstance(hypothesis, str):\n",
    "        hypothesis = text_field.tokenize(hypothesis)\n",
    "    \n",
    "    if text_field.lower:\n",
    "        premise = [t.lower() for t in premise]\n",
    "        hypothesis = [t.lower() for t in hypothesis]\n",
    "        \n",
    "    premise = [text_field.vocab.stoi[t] for t in premise]\n",
    "    hypothesis = [text_field.vocab.stoi[t] for t in hypothesis]\n",
    "    \n",
    "    premise = torch.LongTensor(premise).unsqueeze(1).to(device)\n",
    "    hypothesis = torch.LongTensor(hypothesis).unsqueeze(1).to(device)\n",
    "    \n",
    "    prediction = model(premise, hypothesis)\n",
    "    \n",
    "    prediction = prediction.argmax(dim=-1).item()\n",
    "    \n",
    "    return label_field.vocab.itos[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "premise = 'a man sitting on a green bench.'\n",
    "hypothesis = 'a woman sitting on a green bench.'\n",
    "for i in range(750):\n",
    "    predict_inference(premise, hypothesis, TEXT, LABEL, model, device)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise = 'Move the sun to the right and above.'\n",
    "hypothesis = 'A user wants to increase the sound.'\n",
    "\n",
    "predict_inference(premise, hypothesis, TEXT, LABEL, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise = 'Move the sun to the right'\n",
    "hypothesis = 'A user wants the sun to move to the right.'\n",
    "\n",
    "predict_inference(premise, hypothesis, TEXT, LABEL, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise = 'a man sitting on a green bench.'\n",
    "hypothesis = 'a person on a park bench'\n",
    "\n",
    "predict_inference(premise, hypothesis, TEXT, LABEL, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitetuningpretrained pytorch from scratch\n",
    "#del model\n",
    "del criterion\n",
    "#del batch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
